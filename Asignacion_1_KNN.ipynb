{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c774c713",
   "metadata": {},
   "source": [
    "## Descripción del dataset: Pima Indians Diabetes\n",
    "\n",
    "El **Pima Indians Diabetes Dataset** es un conjunto de datos clásico en Machine Learning y bioestadística, recopilado por el *National Institute of Diabetes and Digestive and Kidney Diseases*.  \n",
    "Su propósito es **predecir la aparición de diabetes tipo 2** en mujeres de origen **pima** (una población indígena del sur de Arizona, EE.UU.), a partir de diversas variables clínicas y demográficas.\n",
    "\n",
    "### Características principales:\n",
    "- **Número de registros:** 392 (en esta versión limpia, el original tenía 768).  \n",
    "- **Número de atributos (features):** 8 variables predictoras + 1 variable objetivo.  \n",
    "- **Población:** Mujeres de al menos 21 años de edad de la etnia Pima.  \n",
    "- **Tarea principal:** Clasificación binaria → determinar si una paciente tiene diabetes (`Outcome = 1`) o no (`Outcome = 0`).\n",
    "\n",
    "### Variables:\n",
    "1. **Pregnancies** → Número de embarazos.  \n",
    "2. **Glucose** → Concentración de glucosa en plasma después de 2 horas en una prueba de tolerancia a la glucosa.  \n",
    "3. **BloodPressure** → Presión arterial diastólica (mm Hg).  \n",
    "4. **SkinThickness** → Espesor del pliegue cutáneo del tríceps (mm).  \n",
    "5. **Insulin** → Nivel sérico de insulina (mu U/ml).  \n",
    "6. **BMI** → Índice de masa corporal (peso en kg / altura² en m²).  \n",
    "7. **DiabetesPedigreeFunction** → Probabilidad de diabetes basada en antecedentes familiares.  \n",
    "8. **Age** → Edad en años.  \n",
    "9. **Outcome** → Variable objetivo:  \n",
    "   - `0` = No tiene diabetes  \n",
    "   - `1` = Tiene diabetes  \n",
    "\n",
    "### Relevancia:\n",
    "Este dataset es ampliamente utilizado en cursos de **Inteligencia Artificial y Machine Learning** para enseñar:\n",
    "- Procesamiento y limpieza de datos biomédicos.  \n",
    "- Métodos de clasificación supervisada (KNN, regresión logística, Random Forest, SVM, redes neuronales, etc.).  \n",
    "- Importancia de la normalización y estandarización en algoritmos basados en distancias.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e89ef96",
   "metadata": {},
   "source": [
    "## Paso 1: Cargar la base de datos  \n",
    "Cargamos el CSV en un `DataFrame` de `pandas`. Si tu archivo no se llama exactamente `cleaned_dataset.csv`, ajusta la ruta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17934010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>Blood Pressure</th>\n",
       "      <th>Skin Thickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Diabetes Pedigree Function</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>129</td>\n",
       "      <td>110</td>\n",
       "      <td>46</td>\n",
       "      <td>130</td>\n",
       "      <td>67.1</td>\n",
       "      <td>0.319</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>78</td>\n",
       "      <td>63</td>\n",
       "      <td>14</td>\n",
       "      <td>59.4</td>\n",
       "      <td>2.420</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>100</td>\n",
       "      <td>35</td>\n",
       "      <td>240</td>\n",
       "      <td>57.3</td>\n",
       "      <td>0.880</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>88</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "      <td>99</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.496</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>162</td>\n",
       "      <td>76</td>\n",
       "      <td>56</td>\n",
       "      <td>100</td>\n",
       "      <td>53.2</td>\n",
       "      <td>0.759</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pregnancies  Glucose  Blood Pressure  Skin Thickness  Insulin   BMI  \\\n",
       "0            0      129             110              46      130  67.1   \n",
       "1            0      180              78              63       14  59.4   \n",
       "2            3      123             100              35      240  57.3   \n",
       "3            1       88              30              42       99  55.0   \n",
       "4            0      162              76              56      100  53.2   \n",
       "\n",
       "   Diabetes Pedigree Function  Age  Outcome  \n",
       "0                       0.319   26        1  \n",
       "1                       2.420   25        1  \n",
       "2                       0.880   22        0  \n",
       "3                       0.496   26        1  \n",
       "4                       0.759   25        1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('dataset/cleaned_dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34b7ef2",
   "metadata": {},
   "source": [
    "## Paso 2: Crear subconjuntos con 20 datos de **entrenamiento** y 20 de **testeo**\n",
    "Seleccionaremos 40 muestras: 20 para entrenar y 20 para evaluar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cce560c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(     Pregnancies  Glucose  Blood Pressure  Skin Thickness  Insulin   BMI  \\\n",
       " 78             2      146              76              35      194  38.2   \n",
       " 274            7       83              78              26       71  29.3   \n",
       " 246            0      120              74              18       63  30.5   \n",
       " 55             0       91              68              32      210  39.9   \n",
       " 387            1       92              62              25       41  19.5   \n",
       " \n",
       "      Diabetes Pedigree Function  Age  Outcome  \n",
       " 78                        0.329   29        0  \n",
       " 274                       0.767   36        0  \n",
       " 246                       0.285   26        0  \n",
       " 55                        0.381   25        0  \n",
       " 387                       0.482   25        0  ,\n",
       "      Pregnancies  Glucose  Blood Pressure  Skin Thickness  Insulin   BMI  \\\n",
       " 15             0      118              84              47      230  45.8   \n",
       " 388            1      100              74              12       46  19.5   \n",
       " 345            7      195              70              33      145  25.1   \n",
       " 0              0      129             110              46      130  67.1   \n",
       " 140            5      136              84              41       88  35.0   \n",
       " \n",
       "      Diabetes Pedigree Function  Age  Outcome  \n",
       " 15                        0.551   31        1  \n",
       " 388                       0.149   28        0  \n",
       " 345                       0.163   55        1  \n",
       " 0                         0.319   26        1  \n",
       " 140                       0.286   35        1  )"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seleccionar 40 muestras aleatorias\n",
    "subset = df.sample(n=40, random_state=42)\n",
    "\n",
    "# Dividir en 20 entrenamiento y 20 testeo\n",
    "train = subset.iloc[:20]\n",
    "test = subset.iloc[20:]\n",
    "\n",
    "train.head(), test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b1e8d1",
   "metadata": {},
   "source": [
    "## Paso 3: Implementar la función de distancia euclidiana\n",
    "\n",
    "**Instrucciones:**\n",
    "- Escribe una función en Python que reciba dos vectores y calcule la distancia euclidiana entre ellos.\n",
    "- Utiliza la siguiente fórmula matemática para la distancia euclidiana entre dos vectores $x$ y $y$ de $n$ dimensiones:\n",
    "\n",
    "$$\n",
    "d(x, y) = \\sqrt{\\sum_{i=1}^{n} (x_i - y_i)^2}\n",
    "$$\n",
    "\n",
    "- Prueba tu función con los siguientes dos ejemplos (cada vector corresponde a una fila del dataset):\n",
    "\n",
    "| Embarazos | Glucosa | Presión Arterial | Grosor Piel | Insulina | IMC  | Función Hereditaria | Edad | Resultado |\n",
    "|-----------|---------|------------------|-------------|----------|------|---------------------|------|-----------|\n",
    "|     1     |   106   |        70        |      28     |   135    | 34.2 |        0.142        |  22  |     0     |\n",
    "|     2     |   102   |        86        |      36     |   120    | 45.5 |        0.127        |  23  |     1     |\n",
    "\n",
    "- Calcula la distancia euclidiana a mano y luego verifica que el resultado de tu función sea el mismo.\n",
    "- La función debe imprimir el resultado del cálculo de la distancia euclidiana con los datos presentados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7aa56bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(48.51607242965984)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def euclidean_distance(x, y):\n",
    "    return np.sqrt(np.sum((x - y) ** 2))\n",
    "\n",
    "# Ejemplo de prueba:\n",
    "vec1 = np.array([2, 146, 76, 35, 194, 38.2, 0.329, 29])\n",
    "vec2 = np.array([0, 118, 84, 47, 230, 45.8, 0.551, 31])\n",
    "\n",
    "dist = euclidean_distance(vec1, vec2)\n",
    "dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc73bbcc",
   "metadata": {},
   "source": [
    "## Paso 4: Implementar un clasificador KNN básico\n",
    "\n",
    "**Instrucciones:**\n",
    "- Escribe una función que, dado un punto de prueba, calcule la distancia a todos los puntos de entrenamiento utilizando tu función de distancia euclidiana.\n",
    "- Selecciona los **k = 3** vecinos más cercanos y predice la clase mayoritaria entre ellos.\n",
    "- Aplica tu función a las 10 muestras de prueba obtenidas previamente, utilizando las 10 muestras de entrenamiento como referencia.\n",
    "- El script debe imprimir una tabla comparando el valor real de `Resultado` de cada muestra de prueba con el valor predicho por tu algoritmo.\n",
    "- Considere que las tablas se pueden codificar con un formato similar al que se muestra en el siguiente código:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89d1223c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementar un clasificador KNN básico\n",
    "\n",
    "def knn_predict(test_row, train_data, train_labels, k=3):\n",
    "    distances = []\n",
    "    for idx, row in train_data.iterrows():\n",
    "        dist = euclidean_distance(test_row, row)\n",
    "        distances.append((dist, train_labels.iloc[idx]))\n",
    "    distances.sort(key=lambda x: x[0])\n",
    "    neighbors = [label for _, label in distances[:k]]\n",
    "    # Predicción: mayoría\n",
    "    return max(set(neighbors), key=neighbors.count)\n",
    "\n",
    "# Ejemplo de uso:\n",
    "# test_row = test.iloc[0][:-1]  # Excluye Outcome\n",
    "# train_data = train.iloc[:, :-1]\n",
    "# train_labels = train['Outcome']\n",
    "# pred = knn_predict(test_row, train_data, train_labels, k=3)\n",
    "# pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494f7f05",
   "metadata": {},
   "source": [
    "## Paso 5: Usar toda la data con separación 80% entrenamiento / 20% testeo  \n",
    "\n",
    "### Pasos:\n",
    "1. Cargar todo el dataset.  \n",
    "2. Separar variables (X) y etiquetas (y).  \n",
    "3. Aplicar `train_test_split` con 80% para entrenamiento y 20% para testeo.  \n",
    "4. Mantener la proporción de clases usando estratificación.  \n",
    "5. Guardar los conjuntos de datos para usarlos en KNN.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8e3b9b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((313, 8), (79, 8))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separar el dataset completo en 80% entrenamiento y 20% testeo\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.iloc[:, :-1]  # Todas las columnas menos Outcome\n",
    "y = df['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb071d8",
   "metadata": {},
   "source": [
    "## Paso 6: Entrenar un KNN con los datos sin escalar (crudos) y calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Definir el valor de **k = 3** y el metodo **Euclidiano**.  \n",
    "2. Entrenar el modelo KNN con los datos crudos (sin normalizar/estandarizar).  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** comparando predicciones con etiquetas reales.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1842e010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7088607594936709"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar y evaluar KNN con datos crudos (sin escalar)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "knn_raw = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_raw.fit(X_train, y_train)\n",
    "pred_raw = knn_raw.predict(X_test)\n",
    "\n",
    "accuracy_raw = accuracy_score(y_test, pred_raw)\n",
    "accuracy_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82664821",
   "metadata": {},
   "source": [
    "## Paso 7: Normalizar (Min-Max scaling) y entrenar KNN, luego calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Aplicar **normalización Min-Max** a los datos de entrenamiento y test.  \n",
    "2. Entrenar el modelo KNN con los datos normalizados.  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** del modelo.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "32694423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7721518987341772"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizar datos con Min-Max scaling y entrenar KNN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_norm = scaler.fit_transform(X_train)\n",
    "X_test_norm = scaler.transform(X_test)\n",
    "\n",
    "knn_norm = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_norm.fit(X_train_norm, y_train)\n",
    "pred_norm = knn_norm.predict(X_test_norm)\n",
    "\n",
    "accuracy_norm = accuracy_score(y_test, pred_norm)\n",
    "accuracy_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6519b",
   "metadata": {},
   "source": [
    "## Paso 9: Estandarizar (Z-score) y entrenar KNN, luego calcular accuracy  \n",
    "\n",
    "### Pasos:\n",
    "1. Aplicar **estandarización Z-score** a los datos de entrenamiento y test.  \n",
    "2. Entrenar el modelo KNN con los datos estandarizados.  \n",
    "3. Predecir las clases del conjunto de test.  \n",
    "4. Calcular el **accuracy** del modelo.  \n",
    "5. Guardar el resultado para la tabla comparativa.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10afcc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.759493670886076"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estandarizar datos con Z-score y entrenar KNN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler_z = StandardScaler()\n",
    "X_train_z = scaler_z.fit_transform(X_train)\n",
    "X_test_z = scaler_z.transform(X_test)\n",
    "\n",
    "knn_z = KNeighborsClassifier(n_neighbors=3, metric='euclidean')\n",
    "knn_z.fit(X_train_z, y_train)\n",
    "pred_z = knn_z.predict(X_test_z)\n",
    "\n",
    "accuracy_z = accuracy_score(y_test, pred_z)\n",
    "accuracy_z"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58946086",
   "metadata": {},
   "source": [
    "## Paso 10/11: Tabla comparativa de accuracies  \n",
    "\n",
    "### Pasos:\n",
    "1. Reunir los resultados de accuracy de cada experimento:  \n",
    "   - KNN sin escalar (80/20).  \n",
    "   - KNN normalizado (80/20).  \n",
    "   - KNN estandarizado (80/20).  \n",
    "2. Crear una tabla con los resultados.  \n",
    "3. Comparar el desempeño de cada método.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e671386b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Método</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN crudo</td>\n",
       "      <td>0.708861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KNN normalizado</td>\n",
       "      <td>0.772152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN estandarizado</td>\n",
       "      <td>0.759494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Método  Accuracy\n",
       "0          KNN crudo  0.708861\n",
       "1    KNN normalizado  0.772152\n",
       "2  KNN estandarizado  0.759494"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tabla comparativa de accuracies\n",
    "import pandas as pd\n",
    "\n",
    "results = pd.DataFrame({\n",
    "    'Método': ['KNN crudo', 'KNN normalizado', 'KNN estandarizado'],\n",
    "    'Accuracy': [accuracy_raw, accuracy_norm, accuracy_z]\n",
    "})\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cafd7a",
   "metadata": {},
   "source": [
    "---\n",
    "## Preguntas de reflexión y aplicación\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351bf383",
   "metadata": {},
   "source": [
    "1. ¿Por qué es importante normalizar o estandarizar los datos antes de usar KNN?  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82ee450",
   "metadata": {},
   "source": [
    "Es importante normalizar o estandarizar los datos antes de usar KNN porque este algoritmo calcula distancias entre puntos. Si las variables tienen diferentes escalas, las de mayor rango dominarán el cálculo de distancia y el modelo será sesgado. Normalizar o estandarizar asegura que todas las variables contribuyan de manera equilibrada, mejorando la precisión y la interpretación del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3393faba",
   "metadata": {},
   "source": [
    "2. ¿Qué diferencias observaste en el accuracy entre los datos crudos, normalizados y estandarizados?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c6273f",
   "metadata": {},
   "source": [
    "Al comparar los resultados, se observa que el accuracy mejora al normalizar y estandarizar los datos. El modelo KNN con datos crudos tiene menor precisión porque las variables con mayor rango afectan más el cálculo de distancia. Al aplicar Min-Max o Z-score, el modelo logra un mejor balance y predice con mayor exactitud, como se refleja en la tabla comparativa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2743a4d",
   "metadata": {},
   "source": [
    "3. Si aumentamos el valor de **k** (número de vecinos), ¿cómo crees que cambiaría el rendimiento del modelo?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817198b3",
   "metadata": {},
   "source": [
    "Si aumentamos el valor de k, el modelo se vuelve menos sensible a valores atípicos y el resultado depende más de la mayoría de los vecinos. Esto puede mejorar la estabilidad y reducir el sobreajuste, pero si k es demasiado grande, el modelo puede perder capacidad de distinguir clases minoritarias y disminuir su precisión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a02e07",
   "metadata": {},
   "source": [
    "4. ¿Qué ventaja tiene implementar KNN manualmente antes de usar scikit-learn?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439b32f9",
   "metadata": {},
   "source": [
    "Implementar KNN manualmente permite comprender a fondo cómo funciona el algoritmo, cómo se calculan las distancias y cómo se seleccionan los vecinos. Esto ayuda a detectar posibles errores, ajustar el método según el problema y aprender los fundamentos antes de usar herramientas automáticas como scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc53e18",
   "metadata": {},
   "source": [
    "5. ¿Qué limitaciones presenta KNN cuando se aplica a conjuntos de datos grandes o con muchas dimensiones?  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76827e64",
   "metadata": {},
   "source": [
    "KNN presenta limitaciones en conjuntos de datos grandes porque requiere calcular distancias entre todos los puntos, lo que es costoso en tiempo y memoria. Además, en datos con muchas dimensiones, la distancia pierde significado (problema de la \"maldición de la dimensionalidad\"), lo que puede reducir la precisión y dificultar la clasificación."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5707edf3",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd6c9c",
   "metadata": {},
   "source": [
    "## Rúbrica de evaluación: Práctica KNN\n",
    "\n",
    "| Criterio | Descripción | Puntaje Máximo |\n",
    "|----------|-------------|----------------|\n",
    "| **1. Carga y exploración del dataset** | Carga correcta del archivo CSV, explicación de las variables y verificación de datos. | 15 pts |\n",
    "| **2. Implementación manual de KNN** | Código propio para calcular distancias euclidianas, selección de vecinos y votación mayoritaria. | 20 pts |\n",
    "| **3. Predicción individual (ejemplo aleatorio)** | Explicación clara del proceso paso a paso para un ejemplo de test. | 10 pts |\n",
    "| **4. Uso de scikit-learn (KNN)** | Entrenamiento y evaluación con `train_test_split`, comparación con el método manual. | 15 pts |\n",
    "| **5. Normalización y estandarización** | Aplicación correcta de Min-Max y Z-score, con cálculo de accuracy en cada caso. | 20 pts |\n",
    "| **6. Tabla comparativa de accuracies** | Presentación clara de los resultados y comparación entre métodos. | 10 pts |\n",
    "| **7. Reflexión y preguntas finales** | Respuestas a las preguntas de análisis planteadas (profundidad y claridad). | 10 pts |\n",
    "\n",
    "**Total: 100 pts**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
